---
title: "Part 2 -- Web scraping practice"
author: Anthony Pulvino
---

```{r run this first}
#install.packages("rvest")
library(rvest) # Web scraping
#install.packages("tidyverse")
library(tidyverse) # Data wrangling
#install.packages("RCurl")
library(RCurl) # Downloading files from the internet

```

# Part 2: Web scraping practice

Below you will find some web scraping challenges that cover important concepts from Part 1.

These challenges are for a website we haven't scraped yet, thegradcafe.com, which is primarily a forum for prospective and current grad students. You might remember browsing it to find out when people were getting notifications.

We will scrape its blog.



## Challenge 1
Modify the rule below to list the titles of all the blog posts on the first page found at the url:

```{r Challenge 1}

url <- "https://forum.thegradcafe.com/"

rule <- "#ipsLayout_mainArea > section"

read_html(url) %>% 
  html_nodes(rule) %>%
  html_text()

```



## Challenge 2
Modify the rule below to make a dataframe consisting of the titles, links, author, and date. The author and date will require you to use Inspector view to build and test two more rules.

```{r Challenge 2}

url <- "https://forum.thegradcafe.com"

# rule
rule <- "#ipsLayout_mainArea > section > ol > li > ol > li > ul > li.ipsDataItem_lastPoster__title > a"

author_rule <- ""

date_rule <- ""

titles <- read_html(url) %>% 
  html_nodes(rule) %>%
  html_text()

links <- read_html(url) %>% 
  html_nodes(rule) %>%
  html_attr('href')

# authors <- 

# dates <- 

# df <- data.frame(titles, links, authors, dates, stringsAsFactors = FALSE)

## Hint: take a look at the last <li> attribute
##        think about how you can changing that might allow you to add to the final <a> attribute to specify either date or time.
## I encourage you to play with the selector tool to generate some ideas or alternative solutions!

```



## Challenge 3
Now that we can extract data from one page, let's make sure we can get every page.
Write a function that lists every page of recently online users (link=https://forum.thegradcafe.com/online/).

For ideas, take a look at the URL structure:

```
<a href="https://forum.thegradcafe.com/online/?page=2" data-page="2">2</a>
```

```{r Challenge 3}
# for a sample answer, see the repo

## YOUR CODE HERE

```
